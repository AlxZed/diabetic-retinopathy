# -*- coding: utf-8 -*-
"""Version with WandB Config.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qOok_rLlno4FklsKjPyOCIcqhkkxjVWT

# CUDA
"""

import torch
import torchvision
import numpy as np

DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

print(torch.cuda.get_device_name(0))

"""# Drive"""

!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

def backup_a_file(file_title, file_location):

  auth.authenticate_user()
  gauth = GoogleAuth()
  gauth.credentials = GoogleCredentials.get_application_default()
  drive = GoogleDrive(gauth)

  file = drive.CreateFile({'title' : file_title})
  file.SetContentFile(file_location)
  file.Upload()
  
  file_dict = drive.CreateFile({'id': file.get('id')})
  dict_key = (file_dict['id'])
  
  return(file_title, dict_key)

def grab_a_file(file_name_and_extension, file_key):
  auth.authenticate_user()
  gauth = GoogleAuth()
  gauth.credentials = GoogleCredentials.get_application_default()
  drive = GoogleDrive(gauth)

  downloaded = drive.CreateFile({'id':file_key}) 
  downloaded.GetContentFile(file_name_and_extension)   

  return("Server up to date")

grab_a_file('512_EyePacs_split.zip','1tdk9OHAUHwjCS9ETNHDgwtbwA6lMrx5o')

!7z x '512_EyePacs_split.zip'

"""# Model Architecture"""

config = {
    'model': 'densenet121',
    'pretrained': True,
    'batch_size': 32,
    'optimizer': 'adam',
    'lr': 0.01,
    'scheduler': 'CosineAnnealingWarmRestarts',
    'weight_decay': '',
    'added_layers': '',
    'img_size': 512,
    'balanced': True,
    'transformations': 5,
}

"""**Transformations**"""

from torchvision import transforms

_mean = [0.4432, 0.3067, 0.2193]
_std = [0.203, 0.1411, 0.1004]

if config['transformations'] == 5:
  train_trans = transforms.Compose([
      transforms.RandomCrop(256),
      transforms.RandomHorizontalFlip(),
      transforms.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=3),
      transforms.RandomAffine(degrees=(-180, 180),scale=(0.8889, 1.0),shear=(-36, 36)),
      transforms.ColorJitter(contrast=(0.9, 1.1)),
      transforms.ToTensor(),
      transforms.Normalize(_mean, _std),
  ])

val_trans = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(_mean, _std),
])

"""**Weighted Data Loader**"""

from torchvision import datasets
import torch.utils.data

class ImageFolderWithPaths(datasets.ImageFolder):
    """
    Custom dataset that includes image file paths. 
    Extends torchvision.datasets.ImageFolder
    """

    # override the __getitem__ method. this is the method that dataloader calls
    def __getitem__(self, index):

        # this is what ImageFolder normally returns 
        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)

        # the image file path
        path = self.imgs[index][0]

        # make a new tuple that includes original and the path
        tuple_with_path = (original_tuple + (path,))

        return tuple_with_path

train_ds = ImageFolderWithPaths("./train/", transform=train_trans)
val_ds = ImageFolderWithPaths("./val/", transform=val_trans)
test_ds = ImageFolderWithPaths("./test/", transform=val_trans)

print(f'Total Train Images: {len(train_ds)}')
print(f'Total Val Images: {len(val_ds)}')
print(f'Total Test Images: {len(test_ds)}')

# Commented out IPython magic to ensure Python compatibility.
# # Importing package for balancing classes, this sampler oversample infrequent
# # classes and undersample the most frequent
# %%capture
# !git clone https://github.com/ufoym/imbalanced-dataset-sampler.git

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# # Installing package
# !cd imbalanced-dataset-sampler && python setup.py install && pip install .

if config['balanced'] is True:

  from torch.utils.data import DataLoader
  from torchsampler import ImbalancedDatasetSampler
  
  weighted_sampler = True

  if weighted_sampler:
      sampler = ImbalancedDatasetSampler(train_ds)
      shuffle = False
  else:
      sampler = None
      shuffle = True

  train_dl = DataLoader(
      train_ds,
      batch_size=config['batch_size'], 
      num_workers=12,
      pin_memory=True,
      sampler=sampler,
      shuffle=shuffle
  )

  val_dl = DataLoader(
      val_ds,
      batch_size=config['batch_size'],
      num_workers=12,
      shuffle=False,
      pin_memory = True
  )

  test_dl = DataLoader(
      test_ds,
      batch_size=config['batch_size'],
      num_workers=12,
      shuffle=False,
      pin_memory = True
  )

total_train_batches = (len(train_ds))//config['batch_size']
total_val_batches = (len(val_ds))//config['batch_size']

print(f'Total Train Batches: {round(total_train_batches)}')
print(f'Total Val Batches: {round(total_val_batches)}')

"""**Model Loading**"""

from torchvision import models
import torch
import torch.nn as nn

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install efficientnet_pytorch

if config['pretrained'] is True:

  if 'densenet121' in config['model']:
    model = models.densenet121(pretrained=True)

  if 'densenet201' in config['model']:
    model = models.densenet201(pretrained=True)

  elif 'efficientnetb0' in config['model']:
    model = EfficientNet.from_pretrained('efficientnet-b0')

  elif 'efficientnetb1' in config['model']:
    model = EfficientNet.from_pretrained('efficientnet-b1')

  elif 'shufflenet' in config['model']:
    model = torch.hub.load('pytorch/vision:v0.5.0', 'shufflenet_v2_x1_0', pretrained=True)

else:
  if 'densenet121'in config['model']:
    model = models.densenet121(pretrained=False)

  if 'densenet201' in config['model']:
    model = models.densenet201(pretrained=False)

  elif 'efficientnetb0' in config['model']:
    model = EfficientNet.from_name('efficientnet-b0')

  elif 'efficientnetb1' in config['model']:
    model = EfficientNet.from_name('efficientnet-b1')

  elif 'shufflenet' in config['model']:
    model = torch.hub.load('pytorch/vision:v0.5.0', 'shufflenet_v2_x1_0', pretrained=False)

"""**Added Layers**"""

if config['added_layers'] is 'dropout' and config['model'].lower() is 'densenet121':
  num_ftrs = model.classifier.in_features
  model.classifier = nn.Sequential(
      nn.Dropout(0.5),
      nn.Linear(num_ftrs, 1))

if config['added_layers'] is 'linear' and config['model'].lower() is 'densenet121':
  num_ftrs = model.classifier.in_features
  model.classifier = nn.Sequential(
      nn.Linear(num_ftrs, 512),
      nn.Linear(512, 256),
      nn.Linear(256, 5))

"""**Optimizer**"""

def get_trainable(model_params):
    return (p for p in model_params if p.requires_grad)

if config['optimizer'] is 'adam':
  optimizer = torch.optim.Adam(get_trainable(model.parameters()),lr=config['lr'])

"""**Scheduler**"""

from torch.optim import lr_scheduler

if config['scheduler'] is 'StepLR':
  step_size = 5
  gamma = 0.464159
  
  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)
  config['step_size'] = step_size
  config['gamma'] = gamma

elif config['scheduler'] is 'ReduceLROnPlateau':
  mode = 'max'
  factor = 0.25
  patience = 3

  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=mode, factor=factor, patience=patience)
  config['mode'] = mode
  config['factor'] = factor
  config['patience'] = patience

elif config['scheduler'] is 'CosineAnnealingWarmRestarts':
  T_0 = 10
  T_mult = 1
  eta_min = 0
  last_epoch = -1

  scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=T_0, T_mult=T_mult, eta_min=eta_min, last_epoch=last_epoch)
  config['T_0'] = T_0
  config['T_mult'] = T_mult
  config['eta_min'] = eta_min
  config['last_epoch'] = last_epoch

import torch.nn as nn
criterion = nn.CrossEntropyLoss()

model = model.to(DEVICE)

"""**Loading Weigths**"""

config['loaded_weigths'] = '1qmUER0nKKUwhT_Tp6e-hkc0v2rxHDeHR'

if config['loaded_weigths'] is not '':
  grab_a_file('past_weights.pt', config['loaded_weigths'])
  model.load_state_dict(torch.load('past_weights.pt'))

"""**Double Check**"""

config

"""**Training**"""

import datetime
import time
date_object = datetime.date.today()

from datetime import datetime
import pytz
tz_NY = pytz.timezone('America/New_York') 
datetime_NY = datetime.now(tz_NY)

prefix = f"{date_object}_{datetime_NY.strftime('%H:%M:%S')}"
print(prefix)

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install --upgrade wandb
# !wandb login 91b90542bdde4812440c8b554b9376667c28643f

import wandb
wandb.init(project="march_2020", name=prefix, config=config)

epoch_amount = []
train_loss_db = []
train_acc_db = []
val_loss_db = []
val_acc_db = []
loaded_epochs = 0
flag_count = 0
acc_weight_db = {}
N_EPOCHS = 100

# Config is a variable that holds and saves hyperparameters and inputs
config = wandb.config


for epoch in range(N_EPOCHS):

    all_paths = []
    all_ground_truths = []
    all_predictions = []

    c0_total, c1_total, c2_total, c3_total, c4_total = (0,)*5
    c0_acc, c1_acc, c2_acc, c3_acc, c4_acc= (0,)*5
    c0, c1, c2, c3, c4= (0,)*5

    
    # Training

    # activating train mode
    # wandb.watch(model)
    model.train()

    total_loss, n_correct, n_samples = 0.0, 0, 0
    init_time = time.time()

    # X = batch of images, y = labels
    # iterate for every batch of the training dataloader.
    
    for image, label, path in train_dl:

        # send to gpu for computations
        # the model must be on the gpu as well
        image, label = image.to(DEVICE), label.to(DEVICE)

        # zero the gradients of the optimizer
        # to prevent the accumulation of gradients
        # at each step
        optimizer.zero_grad()

        # we pass our data X trough our model
        # and get a prediction y_
        pred_label = model(image)

        # we use the loss function to calculate the loss
        # the difference between the y and y_, the predicted y
        loss = criterion(pred_label, label)

        # backpropagation, gives us the gradients
        loss.backward()

        # we optimize all the parameters of the model
        # the optimizer is define prior.
        optimizer.step()
        scheduler.step()

        _, y_label_ = torch.max(pred_label, 1)
        n_correct += (y_label_ == label).sum().item()
        total_loss += loss.item() * image.shape[0]
        n_samples += image.shape[0]

        train_loss = total_loss / n_samples
        train_acc = n_correct / n_samples * 100

    train_loss_db.append(train_loss)
    train_acc_db.append(train_acc)

    # Eval-------------------------------------------------------------------------------------------

    # activating eval mode, turns off dropout
    # batch norm behaves differently
    model.eval()

    total_loss, n_correct, n_samples = 0.0, 0, 0

    # no_grad = we don't need to track the gradients
    with torch.no_grad():
        # init_time = time.time()

        # iterate for every batch of the eval dataloader.
        for image, label, path in val_dl:
          
            image, label = image.to(DEVICE), label.to(DEVICE)
            pred_label = model(image)
            loss = criterion(pred_label, label)

            # epoch stats
            _, y_label_ = torch.max(pred_label, 1)
            n_correct += (y_label_ == label).sum().item()
            total_loss += loss.item() * image.shape[0]
            n_samples += image.shape[0]

            #passing to cpu
            prediction_cpu = pred_label.cpu().argmax(dim=1, keepdim=True)

            #pulling ground truths from preds
            ground_truths = label.view_as(prediction_cpu)

            #append paths
            for p in path:
              all_paths.append(p)

            #Confusion Matrix
            for gt in ground_truths:
              all_ground_truths.append(gt.item())
            
            for pc in prediction_cpu:
              all_predictions.append(pc.item())

        for a,b,c in zip(all_ground_truths, all_predictions, all_paths):
            real_class = int(c.split('/')[-2])

            if real_class == 0:
              c0_total +=1
              if a == b:
                c0+=1
                c0_acc = round((c0/c0_total)*100, 2)

            elif real_class == 1:
              c1_total +=1
              if a == b:
                c1+=1
                c1_acc = round((c1/c1_total)*100, 2)

            elif real_class == 2:
              c2_total +=1
              if a == b:
                c2+=1
                c2_acc = round((c2/c2_total)*100, 2)

            elif real_class == 3:
              c3_total +=1
              if a == b:
                c3+=1
                c3_acc = round((c3/c3_total)*100, 2)

            elif real_class == 4:
              c4_total += 1
              if a == b:
                c4+=1
                c4_acc = round((c4/c4_total)*100, 2)

            # generating status variables
            epoch_time = time.time() - init_time
            epoch_amount.append(epoch + loaded_epochs + 1)

            val_loss = total_loss / n_samples
            #val_acc = n_correct / n_samples * 100

    val_acc = round(((c0_acc + c1_acc + c2_acc + c3_acc + c4_acc)/5),2)
    val_acc_db.append(val_acc)
    val_loss_db.append(val_loss)

    # get current lr
    for param_group in optimizer.param_groups:
      old_lr = param_group['lr']

    # if epoch_amount[-1] > 1:
    #   if val_acc_db[-1] < (val_acc_db[-2]):
    #     flag_count+=1

    #   if val_acc_db[-1] == (val_acc_db[-2]):
    #     flag_count+=1

    # backup if best acc
    if len(val_acc_db) > 5 and val_acc_db[-1] > max(val_acc_db[:-1]):
      results_prefix = f'{prefix}_{epoch_amount[-1]}_{round(val_acc_db[-1])}%'
      filename_of_state_dict = results_prefix + '_state_dict.pt'
      filename_of_model = results_prefix + '_trained_model.pt'
      torch.save(model.state_dict(), filename_of_state_dict)
      backup_a_file(filename_of_state_dict, './' + filename_of_state_dict)
      acc_weight_db[val_acc_db[-1]] = './'+filename_of_state_dict


      datetime_NY = datetime.now(tz_NY)
    print(
        f"{epoch_amount[-1]}/{N_EPOCHS} | "
        f"{datetime_NY.strftime('%H:%M:%S')} | "
        f"valid acc: {val_acc:9.3f}% | "
        f"current lr: {old_lr:9.8f} | "
        f"flag count: {flag_count} | "
        f"{(epoch_time//60):9.1f}min")

    print(
        f"{epoch_amount[-1]}/{N_EPOCHS} | "
        f"{datetime_NY.strftime('%H:%M:%S')} | "
        f'class 0: {c0_acc}% | '
        f'class 1: {c1_acc}% | '
        f'class 2: {c2_acc}% | '
        f'class 3: {c3_acc}% | '
        f'class 4: {c4_acc}%\n')
    
       # custom scheduler
    # if flag_count == 5:
    #   for param_group in optimizer.param_groups:
    #     new_lr = old_lr * 0.50
    #     param_group['lr'] = new_lr
    #     flag_count = 0
    #     model.load_state_dict(torch.load(acc_weight_db[max(acc_weight_db)]))ooin_loss_db[-1]})

    
    wandb.log({"Val Accuracy": val_acc, "Val Loss": val_loss_db[-1],
               "Train Accuracy": train_acc_db[-1], "Learning Rate": old_lr})

