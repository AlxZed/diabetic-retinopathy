diff --git a/README.md b/README.md
deleted file mode 100644
index 2acc28a..0000000
--- a/README.md
+++ /dev/null
@@ -1 +0,0 @@
-# diabetic-retinopathy
\ No newline at end of file
diff --git a/config.py b/config.py
new file mode 100644
index 0000000..996dab8
--- /dev/null
+++ b/config.py
@@ -0,0 +1,14 @@
+config = {
+    'model': 'densenet121',
+    'pretrained': True,
+    'batch_size': 32,
+    'optimizer': 'adam',
+    'lr': 0.01,
+    'scheduler': 'CosineAnnealingWarmRestarts',
+    'loaded_weigths': '',
+    'weight_decay': '',
+    'added_layers': '',
+    'img_size': 512,
+    'balanced': True,
+    'transformations': 5,
+}
\ No newline at end of file
diff --git a/data_loaders.py b/data_loaders.py
new file mode 100644
index 0000000..6228cb2
--- /dev/null
+++ b/data_loaders.py
@@ -0,0 +1,43 @@
+from torch.utils.data import DataLoader
+from torchsampler import ImbalancedDatasetSampler
+
+
+def get_dataloaders(config, train_ds, val_ds, test_ds):
+
+    if config['balanced'] is True:
+
+        weighted_sampler = True
+
+        if weighted_sampler:
+            sampler = ImbalancedDatasetSampler(train_ds)
+            shuffle = False
+        else:
+            sampler = None
+            shuffle = True
+
+        train_dl = DataLoader(
+                train_ds,
+                batch_size=config['batch_size'],
+                num_workers=12,
+                pin_memory=True,
+                sampler=sampler,
+                shuffle=shuffle
+        )
+
+        val_dl = DataLoader(
+                val_ds,
+                batch_size=config['batch_size'],
+                num_workers=12,
+                shuffle=False,
+                pin_memory=True
+        )
+
+        test_dl = DataLoader(
+                test_ds,
+                batch_size=config['batch_size'],
+                num_workers=12,
+                shuffle=False,
+                pin_memory=True
+        )
+
+    return train_dl, val_dl, test_dl
\ No newline at end of file
diff --git a/main.py b/main.py
new file mode 100644
index 0000000..f0a32bc
--- /dev/null
+++ b/main.py
@@ -0,0 +1,53 @@
+from transformations import get_transformations
+from data_loaders import get_dataloaders
+from model import get_model
+from train import training_loop
+from optimizer_scheduler import get_optimizer, get_scheduler
+from weights import get_weights
+from config import config
+import datetime
+import torch
+import os
+import pytz
+import wandb
+
+
+def intitialize_wandb_session(datetime):
+    date_object = datetime.date.today()
+
+    from datetime import datetime
+    tz_NY = pytz.timezone('America/New_York')
+    datetime_NY = datetime.now(tz_NY)
+    prefix = f"{date_object}_{datetime_NY.strftime('%H:%M:%S')}"
+    config = wandb.config
+    wandb.init(project="march_2020", name=prefix, config=config)
+
+    return prefix
+
+
+def main():
+    train_ds, val_ds, test_ds = get_transformations(config, dataset_path)
+    train_dl, val_dl, test_dl = get_dataloaders(config, train_ds, val_ds, test_ds)
+    model, criterion = get_model(config)
+    optimizer = get_optimizer(config, model)
+    scheduler = get_scheduler(config, optimizer)
+    model = model.to(DEVICE)
+    get_weights(config, model)
+    training_loop(model, optimizer, scheduler, val_dl, train_dl, criterion, config, DEVICE, prefix, tz_NY)
+
+
+if __name__ == '__main__':
+
+    # logging wandb session
+    os.system("wandb login 91b90542bdde4812440c8b554b")
+
+    # # initialize CUDA
+    # DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
+    # print(torch.cuda.get_device_name(0))
+
+    #dataset path
+    dataset_path = './Desktop/'
+
+    prefix = intitialize_wandb_session(datetime)
+
+    main()
diff --git a/model.py b/model.py
new file mode 100644
index 0000000..14ee94f
--- /dev/null
+++ b/model.py
@@ -0,0 +1,57 @@
+from efficientnet_pytorch import EfficientNet
+from torchvision import models
+import torch
+import torch.nn as nn
+
+
+def get_model(config):
+
+    criterion = nn.CrossEntropyLoss()
+
+    if config['pretrained'] is True:
+
+      if 'densenet121' in config['model']:
+        model = models.densenet121(pretrained=True)
+
+      if 'densenet201' in config['model']:
+        model = models.densenet201(pretrained=True)
+
+      elif 'efficientnetb0' in config['model']:
+        model = EfficientNet.from_pretrained('efficientnet-b0')
+
+      elif 'efficientnetb1' in config['model']:
+        model = EfficientNet.from_pretrained('efficientnet-b1')
+
+      elif 'shufflenet' in config['model']:
+        model = torch.hub.load('pytorch/vision:v0.5.0', 'shufflenet_v2_x1_0', pretrained=True)
+
+    else:
+      if 'densenet121'in config['model']:
+        model = models.densenet121(pretrained=False)
+
+      if 'densenet201' in config['model']:
+        model = models.densenet201(pretrained=False)
+
+      elif 'efficientnetb0' in config['model']:
+        model = EfficientNet.from_name('efficientnet-b0')
+
+      elif 'efficientnetb1' in config['model']:
+        model = EfficientNet.from_name('efficientnet-b1')
+
+      elif 'shufflenet' in config['model']:
+        model = torch.hub.load('pytorch/vision:v0.5.0', 'shufflenet_v2_x1_0', pretrained=False)
+
+    if config['added_layers'] is 'dropout' and config['model'].lower() is 'densenet121':
+      num_ftrs = model.classifier.in_features
+      model.classifier = nn.Sequential(
+          nn.Dropout(0.5),
+          nn.Linear(num_ftrs, 1))
+
+    if config['added_layers'] is 'linear' and config['model'].lower() is 'densenet121':
+      num_ftrs = model.classifier.in_features
+      model.classifier = nn.Sequential(
+          nn.Linear(num_ftrs, 512),
+          nn.Linear(512, 256),
+          nn.Linear(256, 5))
+
+    return model, criterion
diff --git a/optimizer_scheduler.py b/optimizer_scheduler.py
new file mode 100644
index 0000000..141a142
--- /dev/null
+++ b/optimizer_scheduler.py
@@ -0,0 +1,47 @@
+import torch
+from torch.optim import lr_scheduler
+
+
+def get_trainable(model_params):
+    return (p for p in model_params if p.requires_grad)
+
+
+def get_optimizer(config, model):
+    if config['optimizer'] is 'adam':
+        optimizer = torch.optim.Adam(get_trainable(model.parameters()), lr=config['lr'])
+        return optimizer
+
+
+def get_scheduler(config, optimizer):
+    if config['scheduler'] is 'StepLR':
+        step_size = 5
+        gamma = 0.464159
+
+        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)
+        config['step_size'] = step_size
+        config['gamma'] = gamma
+
+    elif config['scheduler'] is 'ReduceLROnPlateau':
+        mode = 'max'
+        factor = 0.25
+        patience = 3
+
+        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=mode, factor=factor, patience=patience)
+        config['mode'] = mode
+        config['factor'] = factor
+        config['patience'] = patience
+
+    elif config['scheduler'] is 'CosineAnnealingWarmRestarts':
+        T_0 = 10
+        T_mult = 1
+        eta_min = 0
+        last_epoch = -1
+
+        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=T_0, T_mult=T_mult, eta_min=eta_min,
+                                                             last_epoch=last_epoch)
+        config['T_0'] = T_0
+        config['T_mult'] = T_mult
+        config['eta_min'] = eta_min
+        config['last_epoch'] = last_epoch
+
+    return scheduler
\ No newline at end of file
diff --git a/requirements.txt b/requirements.txt
new file mode 100644
index 0000000..5347ed2
--- /dev/null
+++ b/requirements.txt
@@ -0,0 +1,92 @@
+alembic==1.4.1
+appdirs==1.4.3
+attrs==19.3.0
+audioread==2.1.8
+certifi==2019.11.28
+cffi==1.14.0
+chardet==3.0.4
+click==7.1.1
+cloudpickle==1.3.0
+configparser==4.0.2
+cycler==0.10.0
+databricks-cli==0.9.1
+decorator==4.4.2
+docker==4.2.0
+docker-pycreds==0.4.0
+efficientnet-pytorch==0.6.3
+entrypoints==0.3
+filelock==3.0.12
+flake8==3.7.9
+Flask==1.1.1
+gitdb==4.0.2
+GitPython==3.1.0
+gorilla==0.3.0
+gql==0.2.0
+graphql-core==1.1
+gunicorn==20.0.4
+idna==2.9
+importlib-metadata==1.5.0
+itsdangerous==1.1.0
+Jinja2==2.11.1
+joblib==0.14.1
+kiwisolver==1.1.0
+librosa==0.7.2
+llvmlite==0.31.0
+Mako==1.1.2
+MarkupSafe==1.1.1
+matplotlib==3.2.1
+mccabe==0.6.1
+mlflow==1.7.1
+more-itertools==8.2.0
+numba==0.48.0
+numpy==1.18.2
+nvidia-ml-py3==7.352.0
+orion==0.1.7
+packaging==20.3
+pandas==1.0.3
+pathtools==0.1.2
+Pillow==7.0.0
+pluggy==0.13.1
+prometheus-client==0.7.1
+prometheus-flask-exporter==0.13.0
+promise==2.3
+protobuf==3.11.3
+psutil==5.7.0
+py==1.8.1
+pycodestyle==2.5.0
+pycparser==2.20
+pyflakes==2.1.1
+pymongo==3.10.1
+pyparsing==2.4.6
+pytest==5.4.1
+python-dateutil==2.8.1
+python-editor==1.0.4
+pytz==2019.3
+PyYAML==5.3.1
+querystring-parser==1.2.4
+requests==2.23.0
+resampy==0.2.2
+scikit-learn==0.22.2.post1
+scipy==1.4.1
+sentry-sdk==0.14.3
+shortuuid==1.0.1
+simplejson==3.17.0
+six==1.14.0
+smmap==3.0.1
+SoundFile==0.10.3.post1
+SQLAlchemy==1.3.13
+sqlparse==0.3.1
+subprocess32==3.5.4
+tabulate==0.8.6
+torch==1.4.0
+torchaudio==0.4.0
+torchsampler==0.1
+torchvision==0.5.0
+tqdm==4.43.0
+urllib3==1.25.8
+wandb==0.8.30
+watchdog==0.10.2
+wcwidth==0.1.8
+websocket-client==0.57.0
+Werkzeug==1.0.0
+zipp==3.1.0
diff --git a/train.py b/train.py
new file mode 100644
index 0000000..a55b415
--- /dev/null
+++ b/train.py
@@ -0,0 +1,213 @@
+import wandb
+import datetime
+import time
+import torch
+
+
+def training_loop(model, optimizer, scheduler, val_dl, train_dl, criterion, config, DEVICE, prefix, tz_NY):
+
+    epoch_amount = []
+    train_loss_db = []
+    train_acc_db = []
+    val_loss_db = []
+    val_acc_db = []
+    loaded_epochs = 0
+    flag_count = 0
+    acc_weight_db = {}
+    N_EPOCHS = 100
+
+
+    for epoch in range(N_EPOCHS):
+
+        all_paths = []
+        all_ground_truths = []
+        all_predictions = []
+
+        c0_total, c1_total, c2_total, c3_total, c4_total = (0,) * 5
+        c0_acc, c1_acc, c2_acc, c3_acc, c4_acc = (0,) * 5
+        c0, c1, c2, c3, c4 = (0,) * 5
+
+        # Training
+
+        # activating train mode
+        # wandb.watch(model)
+        model.train()
+
+        total_loss, n_correct, n_samples = 0.0, 0, 0
+        init_time = time.time()
+
+        # X = batch of images, y = labels
+        # iterate for every batch of the training dataloader.
+
+        for image, label, path in train_dl:
+            # send to gpu for computations
+            # the model must be on the gpu as well
+            image, label = image.to(DEVICE), label.to(DEVICE)
+
+            # zero the gradients of the optimizer
+            # to prevent the accumulation of gradients
+            # at each step
+            optimizer.zero_grad()
+
+            # we pass our data X trough our model
+            # and get a prediction y_
+            pred_label = model(image)
+
+            # we use the loss function to calculate the loss
+            # the difference between the y and y_, the predicted y
+            loss = criterion(pred_label, label)
+
+            # backpropagation, gives us the gradients
+            loss.backward()
+
+            # we optimize all the parameters of the model
+            # the optimizer is define prior.
+            optimizer.step()
+            scheduler.step()
+
+            _, y_label_ = torch.max(pred_label, 1)
+            n_correct += (y_label_ == label).sum().item()
+            total_loss += loss.item() * image.shape[0]
+            n_samples += image.shape[0]
+
+            train_loss = total_loss / n_samples
+            train_acc = n_correct / n_samples * 100
+
+        train_loss_db.append(train_loss)
+        train_acc_db.append(train_acc)
+
+        # Eval-------------------------------------------------------------------------------------------
+
+        # activating eval mode, turns off dropout
+        # batch norm behaves differently
+        model.eval()
+
+        total_loss, n_correct, n_samples = 0.0, 0, 0
+
+        # no_grad = we don't need to track the gradients
+        with torch.no_grad():
+            # init_time = time.time()
+
+            # iterate for every batch of the eval dataloader.
+            for image, label, path in val_dl:
+
+                image, label = image.to(DEVICE), label.to(DEVICE)
+                pred_label = model(image)
+                loss = criterion(pred_label, label)
+
+                # epoch stats
+                _, y_label_ = torch.max(pred_label, 1)
+                n_correct += (y_label_ == label).sum().item()
+                total_loss += loss.item() * image.shape[0]
+                n_samples += image.shape[0]
+
+                # passing to cpu
+                prediction_cpu = pred_label.cpu().argmax(dim=1, keepdim=True)
+
+                # pulling ground truths from preds
+                ground_truths = label.view_as(prediction_cpu)
+
+                # append paths
+                for p in path:
+                    all_paths.append(p)
+
+                # Confusion Matrix
+                for gt in ground_truths:
+                    all_ground_truths.append(gt.item())
+
+                for pc in prediction_cpu:
+                    all_predictions.append(pc.item())
+
+            for a, b, c in zip(all_ground_truths, all_predictions, all_paths):
+                real_class = int(c.split('/')[-2])
+
+                if real_class == 0:
+                    c0_total += 1
+                    if a == b:
+                        c0 += 1
+                        c0_acc = round((c0 / c0_total) * 100, 2)
+
+                elif real_class == 1:
+                    c1_total += 1
+                    if a == b:
+                        c1 += 1
+                        c1_acc = round((c1 / c1_total) * 100, 2)
+
+                elif real_class == 2:
+                    c2_total += 1
+                    if a == b:
+                        c2 += 1
+                        c2_acc = round((c2 / c2_total) * 100, 2)
+
+                elif real_class == 3:
+                    c3_total += 1
+                    if a == b:
+                        c3 += 1
+                        c3_acc = round((c3 / c3_total) * 100, 2)
+
+                elif real_class == 4:
+                    c4_total += 1
+                    if a == b:
+                        c4 += 1
+                        c4_acc = round((c4 / c4_total) * 100, 2)
+
+                # generating status variables
+                epoch_time = time.time() - init_time
+                epoch_amount.append(epoch + loaded_epochs + 1)
+
+                val_loss = total_loss / n_samples
+                # val_acc = n_correct / n_samples * 100
+
+        val_acc = round(((c0_acc + c1_acc + c2_acc + c3_acc + c4_acc) / 5), 2)
+        val_acc_db.append(val_acc)
+        val_loss_db.append(val_loss)
+
+        # get current lr
+        for param_group in optimizer.param_groups:
+            old_lr = param_group['lr']
+
+        # if epoch_amount[-1] > 1:
+        #   if val_acc_db[-1] < (val_acc_db[-2]):
+        #     flag_count+=1
+
+        #   if val_acc_db[-1] == (val_acc_db[-2]):
+        #     flag_count+=1
+
+        # backup if best acc
+        if len(val_acc_db) > 5 and val_acc_db[-1] > max(val_acc_db[:-1]):
+            results_prefix = f'{prefix}_{epoch_amount[-1]}_{round(val_acc_db[-1])}%'
+            filename_of_state_dict = results_prefix + '_state_dict.pt'
+            torch.save(model.state_dict(), filename_of_state_dict)
+
+            #filename_of_model = results_prefix + '_trained_model.pt'
+            #acc_weight_db[val_acc_db[-1]] = './' + filename_of_state_dict
+
+            datetime_NY = datetime.now(tz_NY)
+
+        print(
+                f"{epoch_amount[-1]}/{N_EPOCHS} | "
+                f"{datetime_NY.strftime('%H:%M:%S')} | "
+                f"valid acc: {val_acc:9.3f}% | "
+                f"current lr: {old_lr:9.8f} | "
+                f"flag count: {flag_count} | "
+                f"{(epoch_time // 60):9.1f}min")
+
+        print(
+                f"{epoch_amount[-1]}/{N_EPOCHS} | "
+                f"{datetime_NY.strftime('%H:%M:%S')} | "
+                f'class 0: {c0_acc}% | '
+                f'class 1: {c1_acc}% | '
+                f'class 2: {c2_acc}% | '
+                f'class 3: {c3_acc}% | '
+                f'class 4: {c4_acc}%\n')
+
+        # custom scheduler
+        # if flag_count == 5:
+        #   for param_group in optimizer.param_groups:
+        #     new_lr = old_lr * 0.50
+        #     param_group['lr'] = new_lr
+        #     flag_count = 0
+        #     model.load_state_dict(torch.load(acc_weight_db[max(acc_weight_db)]))ooin_loss_db[-1]})
+
+        wandb.log({"Val Accuracy": val_acc, "Val Loss": val_loss_db[-1],
+                   "Train Accuracy": train_acc_db[-1], "Learning Rate": old_lr})
\ No newline at end of file
diff --git a/transformations.py b/transformations.py
new file mode 100644
index 0000000..3009430
--- /dev/null
+++ b/transformations.py
@@ -0,0 +1,54 @@
+from torchvision import transforms
+from torchvision import datasets
+
+
+class ImageFolderWithPaths(datasets.ImageFolder):
+    """
+    Custom dataset that includes image file paths.
+    Extends torchvision.datasets.ImageFolder
+    """
+
+    # override the __getitem__ method. this is the method that dataloader calls
+    def __getitem__(self, index):
+        # this is what ImageFolder normally returns
+        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)
+
+        # the image file path
+        path = self.imgs[index][0]
+
+        # make a new tuple that includes original and the path
+        tuple_with_path = (original_tuple + (path,))
+
+        return tuple_with_path
+
+
+def get_transformations(config, dataset_path):
+
+    _mean = [0.4432, 0.3067, 0.2193]
+    _std = [0.203, 0.1411, 0.1004]
+
+    if config['transformations'] == 5:
+      train_trans = transforms.Compose([
+          transforms.RandomCrop(256),
+          transforms.RandomHorizontalFlip(),
+          transforms.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=3),
+          transforms.RandomAffine(degrees=(-180, 180),scale=(0.8889, 1.0),shear=(-36, 36)),
+          transforms.ColorJitter(contrast=(0.9, 1.1)),
+          transforms.ToTensor(),
+          transforms.Normalize(_mean, _std),
+      ])
+
+    val_trans = transforms.Compose([
+        transforms.ToTensor(),
+        transforms.Normalize(_mean, _std),
+    ])
+
+    train_ds = ImageFolderWithPaths(f"{dataset_path}./train/", transform=train_trans)
+    val_ds = ImageFolderWithPaths(f"{dataset_path}./val/", transform=val_trans)
+    test_ds = ImageFolderWithPaths(f"{dataset_path}./test/", transform=val_trans)
+
+    print(f'Total Train Images: {len(train_ds)}')
+    print(f'Total Val Images: {len(val_ds)}')
+    print(f'Total Test Images: {len(test_ds)}')
+
+    return train_ds, val_ds, test_ds
diff --git a/version_with_wandb_config.py b/version_with_wandb_config.py
deleted file mode 100644
index c7a75b4..0000000
--- a/version_with_wandb_config.py
+++ /dev/null
@@ -1,542 +0,0 @@
-# -*- coding: utf-8 -*-
-"""Version with WandB Config.ipynb
-
-Automatically generated by Colaboratory.
-
-Original file is located at
-    https://colab.research.google.com/drive/1qOok_rLlno4FklsKjPyOCIcqhkkxjVWT
-
-# CUDA
-"""
-
-import torch
-import torchvision
-import numpy as np
-
-DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
-
-print(torch.cuda.get_device_name(0))
-
-"""# Drive"""
-
-!pip install -U -q PyDrive
-from pydrive.auth import GoogleAuth
-from pydrive.drive import GoogleDrive
-from google.colab import auth
-from oauth2client.client import GoogleCredentials
-
-auth.authenticate_user()
-gauth = GoogleAuth()
-gauth.credentials = GoogleCredentials.get_application_default()
-drive = GoogleDrive(gauth)
-
-def backup_a_file(file_title, file_location):
-
-  auth.authenticate_user()
-  gauth = GoogleAuth()
-  gauth.credentials = GoogleCredentials.get_application_default()
-  drive = GoogleDrive(gauth)
-
-  file = drive.CreateFile({'title' : file_title})
-  file.SetContentFile(file_location)
-  file.Upload()
-  
-  file_dict = drive.CreateFile({'id': file.get('id')})
-  dict_key = (file_dict['id'])
-  
-  return(file_title, dict_key)
-
-def grab_a_file(file_name_and_extension, file_key):
-  auth.authenticate_user()
-  gauth = GoogleAuth()
-  gauth.credentials = GoogleCredentials.get_application_default()
-  drive = GoogleDrive(gauth)
-
-  downloaded = drive.CreateFile({'id':file_key}) 
-  downloaded.GetContentFile(file_name_and_extension)   
-
-  return("Server up to date")
-
-grab_a_file('512_EyePacs_split.zip','1tdk9OHAUHwjCS9ETNHDgwtbwA6lMrx5o')
-
-!7z x '512_EyePacs_split.zip'
-
-"""# Model Architecture"""
-
-config = {
-    'model': 'densenet121',
-    'pretrained': True,
-    'batch_size': 32,
-    'optimizer': 'adam',
-    'lr': 0.01,
-    'scheduler': 'CosineAnnealingWarmRestarts',
-    'weight_decay': '',
-    'added_layers': '',
-    'img_size': 512,
-    'balanced': True,
-    'transformations': 5,
-}
-
-"""**Transformations**"""
-
-from torchvision import transforms
-
-_mean = [0.4432, 0.3067, 0.2193]
-_std = [0.203, 0.1411, 0.1004]
-
-if config['transformations'] == 5:
-  train_trans = transforms.Compose([
-      transforms.RandomCrop(256),
-      transforms.RandomHorizontalFlip(),
-      transforms.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=3),
-      transforms.RandomAffine(degrees=(-180, 180),scale=(0.8889, 1.0),shear=(-36, 36)),
-      transforms.ColorJitter(contrast=(0.9, 1.1)),
-      transforms.ToTensor(),
-      transforms.Normalize(_mean, _std),
-  ])
-
-val_trans = transforms.Compose([
-    transforms.ToTensor(),
-    transforms.Normalize(_mean, _std),
-])
-
-"""**Weighted Data Loader**"""
-
-from torchvision import datasets
-import torch.utils.data
-
-class ImageFolderWithPaths(datasets.ImageFolder):
-    """
-    Custom dataset that includes image file paths. 
-    Extends torchvision.datasets.ImageFolder
-    """
-
-    # override the __getitem__ method. this is the method that dataloader calls
-    def __getitem__(self, index):
-
-        # this is what ImageFolder normally returns 
-        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)
-
-        # the image file path
-        path = self.imgs[index][0]
-
-        # make a new tuple that includes original and the path
-        tuple_with_path = (original_tuple + (path,))
-
-        return tuple_with_path
-
-train_ds = ImageFolderWithPaths("./train/", transform=train_trans)
-val_ds = ImageFolderWithPaths("./val/", transform=val_trans)
-test_ds = ImageFolderWithPaths("./test/", transform=val_trans)
-
-print(f'Total Train Images: {len(train_ds)}')
-print(f'Total Val Images: {len(val_ds)}')
-print(f'Total Test Images: {len(test_ds)}')
-
-# Commented out IPython magic to ensure Python compatibility.
-# # Importing package for balancing classes, this sampler oversample infrequent
-# # classes and undersample the most frequent
-# %%capture
-# !git clone https://github.com/ufoym/imbalanced-dataset-sampler.git
-
-# Commented out IPython magic to ensure Python compatibility.
-# %%capture
-# # Installing package
-# !cd imbalanced-dataset-sampler && python setup.py install && pip install .
-
-if config['balanced'] is True:
-
-  from torch.utils.data import DataLoader
-  from torchsampler import ImbalancedDatasetSampler
-  
-  weighted_sampler = True
-
-  if weighted_sampler:
-      sampler = ImbalancedDatasetSampler(train_ds)
-      shuffle = False
-  else:
-      sampler = None
-      shuffle = True
-
-  train_dl = DataLoader(
-      train_ds,
-      batch_size=config['batch_size'], 
-      num_workers=12,
-      pin_memory=True,
-      sampler=sampler,
-      shuffle=shuffle
-  )
-
-  val_dl = DataLoader(
-      val_ds,
-      batch_size=config['batch_size'],
-      num_workers=12,
-      shuffle=False,
-      pin_memory = True
-  )
-
-  test_dl = DataLoader(
-      test_ds,
-      batch_size=config['batch_size'],
-      num_workers=12,
-      shuffle=False,
-      pin_memory = True
-  )
-
-total_train_batches = (len(train_ds))//config['batch_size']
-total_val_batches = (len(val_ds))//config['batch_size']
-
-print(f'Total Train Batches: {round(total_train_batches)}')
-print(f'Total Val Batches: {round(total_val_batches)}')
-
-"""**Model Loading**"""
-
-from torchvision import models
-import torch
-import torch.nn as nn
-
-# Commented out IPython magic to ensure Python compatibility.
-# %%capture
-# !pip install efficientnet_pytorch
-
-if config['pretrained'] is True:
-
-  if 'densenet121' in config['model']:
-    model = models.densenet121(pretrained=True)
-
-  if 'densenet201' in config['model']:
-    model = models.densenet201(pretrained=True)
-
-  elif 'efficientnetb0' in config['model']:
-    model = EfficientNet.from_pretrained('efficientnet-b0')
-
-  elif 'efficientnetb1' in config['model']:
-    model = EfficientNet.from_pretrained('efficientnet-b1')
-
-  elif 'shufflenet' in config['model']:
-    model = torch.hub.load('pytorch/vision:v0.5.0', 'shufflenet_v2_x1_0', pretrained=True)
-
-else:
-  if 'densenet121'in config['model']:
-    model = models.densenet121(pretrained=False)
-
-  if 'densenet201' in config['model']:
-    model = models.densenet201(pretrained=False)
-
-  elif 'efficientnetb0' in config['model']:
-    model = EfficientNet.from_name('efficientnet-b0')
-
-  elif 'efficientnetb1' in config['model']:
-    model = EfficientNet.from_name('efficientnet-b1')
-
-  elif 'shufflenet' in config['model']:
-    model = torch.hub.load('pytorch/vision:v0.5.0', 'shufflenet_v2_x1_0', pretrained=False)
-
-"""**Added Layers**"""
-
-if config['added_layers'] is 'dropout' and config['model'].lower() is 'densenet121':
-  num_ftrs = model.classifier.in_features
-  model.classifier = nn.Sequential(
-      nn.Dropout(0.5),
-      nn.Linear(num_ftrs, 1))
-
-if config['added_layers'] is 'linear' and config['model'].lower() is 'densenet121':
-  num_ftrs = model.classifier.in_features
-  model.classifier = nn.Sequential(
-      nn.Linear(num_ftrs, 512),
-      nn.Linear(512, 256),
-      nn.Linear(256, 5))
-
-"""**Optimizer**"""
-
-def get_trainable(model_params):
-    return (p for p in model_params if p.requires_grad)
-
-if config['optimizer'] is 'adam':
-  optimizer = torch.optim.Adam(get_trainable(model.parameters()),lr=config['lr'])
-
-"""**Scheduler**"""
-
-from torch.optim import lr_scheduler
-
-if config['scheduler'] is 'StepLR':
-  step_size = 5
-  gamma = 0.464159
-  
-  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)
-  config['step_size'] = step_size
-  config['gamma'] = gamma
-
-elif config['scheduler'] is 'ReduceLROnPlateau':
-  mode = 'max'
-  factor = 0.25
-  patience = 3
-
-  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=mode, factor=factor, patience=patience)
-  config['mode'] = mode
-  config['factor'] = factor
-  config['patience'] = patience
-
-elif config['scheduler'] is 'CosineAnnealingWarmRestarts':
-  T_0 = 10
-  T_mult = 1
-  eta_min = 0
-  last_epoch = -1
-
-  scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=T_0, T_mult=T_mult, eta_min=eta_min, last_epoch=last_epoch)
-  config['T_0'] = T_0
-  config['T_mult'] = T_mult
-  config['eta_min'] = eta_min
-  config['last_epoch'] = last_epoch
-
-import torch.nn as nn
-criterion = nn.CrossEntropyLoss()
-
-model = model.to(DEVICE)
-
-"""**Loading Weigths**"""
-
-config['loaded_weigths'] = '1qmUER0nKKUwhT_Tp6e-hkc0v2rxHDeHR'
-
-if config['loaded_weigths'] is not '':
-  grab_a_file('past_weights.pt', config['loaded_weigths'])
-  model.load_state_dict(torch.load('past_weights.pt'))
-
-"""**Double Check**"""
-
-config
-
-"""**Training**"""
-
-import datetime
-import time
-date_object = datetime.date.today()
-
-from datetime import datetime
-import pytz
-tz_NY = pytz.timezone('America/New_York') 
-datetime_NY = datetime.now(tz_NY)
-
-prefix = f"{date_object}_{datetime_NY.strftime('%H:%M:%S')}"
-print(prefix)
-
-# Commented out IPython magic to ensure Python compatibility.
-# %%capture
-# !pip install --upgrade wandb
-# !wandb login 91b90542bdde4812440c8b554b9376667c28643f
-
-import wandb
-wandb.init(project="march_2020", name=prefix, config=config)
-
-epoch_amount = []
-train_loss_db = []
-train_acc_db = []
-val_loss_db = []
-val_acc_db = []
-loaded_epochs = 0
-flag_count = 0
-acc_weight_db = {}
-N_EPOCHS = 100
-
-# Config is a variable that holds and saves hyperparameters and inputs
-config = wandb.config
-
-
-for epoch in range(N_EPOCHS):
-
-    all_paths = []
-    all_ground_truths = []
-    all_predictions = []
-
-    c0_total, c1_total, c2_total, c3_total, c4_total = (0,)*5
-    c0_acc, c1_acc, c2_acc, c3_acc, c4_acc= (0,)*5
-    c0, c1, c2, c3, c4= (0,)*5
-
-    
-    # Training
-
-    # activating train mode
-    # wandb.watch(model)
-    model.train()
-
-    total_loss, n_correct, n_samples = 0.0, 0, 0
-    init_time = time.time()
-
-    # X = batch of images, y = labels
-    # iterate for every batch of the training dataloader.
-    
-    for image, label, path in train_dl:
-
-        # send to gpu for computations
-        # the model must be on the gpu as well
-        image, label = image.to(DEVICE), label.to(DEVICE)
-
-        # zero the gradients of the optimizer
-        # to prevent the accumulation of gradients
-        # at each step
-        optimizer.zero_grad()
-
-        # we pass our data X trough our model
-        # and get a prediction y_
-        pred_label = model(image)
-
-        # we use the loss function to calculate the loss
-        # the difference between the y and y_, the predicted y
-        loss = criterion(pred_label, label)
-
-        # backpropagation, gives us the gradients
-        loss.backward()
-
-        # we optimize all the parameters of the model
-        # the optimizer is define prior.
-        optimizer.step()
-        scheduler.step()
-
-        _, y_label_ = torch.max(pred_label, 1)
-        n_correct += (y_label_ == label).sum().item()
-        total_loss += loss.item() * image.shape[0]
-        n_samples += image.shape[0]
-
-        train_loss = total_loss / n_samples
-        train_acc = n_correct / n_samples * 100
-
-    train_loss_db.append(train_loss)
-    train_acc_db.append(train_acc)
-
-    # Eval-------------------------------------------------------------------------------------------
-
-    # activating eval mode, turns off dropout
-    # batch norm behaves differently
-    model.eval()
-
-    total_loss, n_correct, n_samples = 0.0, 0, 0
-
-    # no_grad = we don't need to track the gradients
-    with torch.no_grad():
-        # init_time = time.time()
-
-        # iterate for every batch of the eval dataloader.
-        for image, label, path in val_dl:
-          
-            image, label = image.to(DEVICE), label.to(DEVICE)
-            pred_label = model(image)
-            loss = criterion(pred_label, label)
-
-            # epoch stats
-            _, y_label_ = torch.max(pred_label, 1)
-            n_correct += (y_label_ == label).sum().item()
-            total_loss += loss.item() * image.shape[0]
-            n_samples += image.shape[0]
-
-            #passing to cpu
-            prediction_cpu = pred_label.cpu().argmax(dim=1, keepdim=True)
-
-            #pulling ground truths from preds
-            ground_truths = label.view_as(prediction_cpu)
-
-            #append paths
-            for p in path:
-              all_paths.append(p)
-
-            #Confusion Matrix
-            for gt in ground_truths:
-              all_ground_truths.append(gt.item())
-            
-            for pc in prediction_cpu:
-              all_predictions.append(pc.item())
-
-        for a,b,c in zip(all_ground_truths, all_predictions, all_paths):
-            real_class = int(c.split('/')[-2])
-
-            if real_class == 0:
-              c0_total +=1
-              if a == b:
-                c0+=1
-                c0_acc = round((c0/c0_total)*100, 2)
-
-            elif real_class == 1:
-              c1_total +=1
-              if a == b:
-                c1+=1
-                c1_acc = round((c1/c1_total)*100, 2)
-
-            elif real_class == 2:
-              c2_total +=1
-              if a == b:
-                c2+=1
-                c2_acc = round((c2/c2_total)*100, 2)
-
-            elif real_class == 3:
-              c3_total +=1
-              if a == b:
-                c3+=1
-                c3_acc = round((c3/c3_total)*100, 2)
-
-            elif real_class == 4:
-              c4_total += 1
-              if a == b:
-                c4+=1
-                c4_acc = round((c4/c4_total)*100, 2)
-
-            # generating status variables
-            epoch_time = time.time() - init_time
-            epoch_amount.append(epoch + loaded_epochs + 1)
-
-            val_loss = total_loss / n_samples
-            #val_acc = n_correct / n_samples * 100
-
-    val_acc = round(((c0_acc + c1_acc + c2_acc + c3_acc + c4_acc)/5),2)
-    val_acc_db.append(val_acc)
-    val_loss_db.append(val_loss)
-
-    # get current lr
-    for param_group in optimizer.param_groups:
-      old_lr = param_group['lr']
-
-    # if epoch_amount[-1] > 1:
-    #   if val_acc_db[-1] < (val_acc_db[-2]):
-    #     flag_count+=1
-
-    #   if val_acc_db[-1] == (val_acc_db[-2]):
-    #     flag_count+=1
-
-    # backup if best acc
-    if len(val_acc_db) > 5 and val_acc_db[-1] > max(val_acc_db[:-1]):
-      results_prefix = f'{prefix}_{epoch_amount[-1]}_{round(val_acc_db[-1])}%'
-      filename_of_state_dict = results_prefix + '_state_dict.pt'
-      filename_of_model = results_prefix + '_trained_model.pt'
-      torch.save(model.state_dict(), filename_of_state_dict)
-      backup_a_file(filename_of_state_dict, './' + filename_of_state_dict)
-      acc_weight_db[val_acc_db[-1]] = './'+filename_of_state_dict
-
-
-      datetime_NY = datetime.now(tz_NY)
-    print(
-        f"{epoch_amount[-1]}/{N_EPOCHS} | "
-        f"{datetime_NY.strftime('%H:%M:%S')} | "
-        f"valid acc: {val_acc:9.3f}% | "
-        f"current lr: {old_lr:9.8f} | "
-        f"flag count: {flag_count} | "
-        f"{(epoch_time//60):9.1f}min")
-
-    print(
-        f"{epoch_amount[-1]}/{N_EPOCHS} | "
-        f"{datetime_NY.strftime('%H:%M:%S')} | "
-        f'class 0: {c0_acc}% | '
-        f'class 1: {c1_acc}% | '
-        f'class 2: {c2_acc}% | '
-        f'class 3: {c3_acc}% | '
-        f'class 4: {c4_acc}%\n')
-    
-       # custom scheduler
-    # if flag_count == 5:
-    #   for param_group in optimizer.param_groups:
-    #     new_lr = old_lr * 0.50
-    #     param_group['lr'] = new_lr
-    #     flag_count = 0
-    #     model.load_state_dict(torch.load(acc_weight_db[max(acc_weight_db)]))ooin_loss_db[-1]})
-
-    
-    wandb.log({"Val Accuracy": val_acc, "Val Loss": val_loss_db[-1],
-               "Train Accuracy": train_acc_db[-1], "Learning Rate": old_lr})
-
diff --git a/weights.py b/weights.py
new file mode 100644
index 0000000..fac6df6
--- /dev/null
+++ b/weights.py
@@ -0,0 +1,7 @@
+import torch
+
+
+def get_weights(config, model):
+
+    if config['loaded_weigths'] is not '':
+      model.load_state_dict(torch.load('./past_weights.pt'))
